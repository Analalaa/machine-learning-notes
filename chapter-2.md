## 过拟合
过拟合是机器学习面临的关键障碍，各类学习算法都必然带有一些针对过拟合的措施
过拟合也是无法彻底避免的，只能“缓解”、减小风险，


## 评估方法
> 对模型的**泛化误差**进行评估，选择最小的那个模型

测试集（testing set）上跑出测试误差（testing error）作为泛化误差的近似。
测试样本通常也从样本真是分布中独立同分布采样得来，但注意要尽可能与训练集（training set）互斥
### 留出法
training set:testing set = 7:3（大约 2/3 ～ 4/5 用于训练）
* 注意保证样本的类别比例相似，例如正反例的比例保持一致啊等等，有很多种划分方法
* 单次使用留出法的估计结果往往不够可靠，一般要采取若干次随机划分、重复进行试验评估后做均值作为评估结果
### k折交叉验证法
数据集划分为k个大小相似的互斥子集，每个子集尽可能保持数据分布的一致性，每次用 k-1 个子集的并集作为训练集，雨下的子集作为测试集
同样通常要随机使用不同的划分方法重复p次，以均值作为k折交叉验证的评估结果
### 自助法
数据集 D，包含 m 个样本，对 D 采样 得到 D'：每次随机从 D 中挑选一个样本，将其深拷贝放入 D'，然后再将该样本放回初始数据集 D 中，是的该样本仍有可能被采样到。
* 自助法在数据集较小、难以有效划分 training/testing 时很有用
* 自助法能从初始数据集中产生多个不同的训练集，这对集成学习有很大好处
* 自助法改变了初始数据集的分布，会引入估计偏差，初始数据量足够时，留出法和交叉验证法更加常用
---
验证集（validation set）是用于模型评估与选择中，用于评估测试的数据集
测试集（testing set）是学得的模型在实际使用中遇到的数据成为测试数据
