## 过拟合
过拟合是机器学习面临的关键障碍，各类学习算法都必然带有一些针对过拟合的措施
过拟合也是无法彻底避免的，只能“缓解”、减小风险，


## 评估方法
> 对模型的**泛化误差**进行评估，选择最小的那个模型

测试集(testing set)上跑出测试误差(testing error)作为泛化误差的近似。
测试样本通常也从样本真是分布中独立同分布采样得来，但注意要尽可能与训练集(training set)互斥

### 留出法
training set:testing set = 7:3(大约 2/3 ～ 4/5 用于训练)
* 注意保证样本的类别比例相似，例如正反例的比例保持一致啊等等，有很多种划分方法
* 单次使用留出法的估计结果往往不够可靠，一般要采取若干次随机划分、重复进行试验评估后做均值作为评估结果

### k折交叉验证法
数据集划分为k个大小相似的互斥子集，每个子集尽可能保持数据分布的一致性，每次用 k-1 个子集的并集作为训练集，余下的子集作为测试集
同样通常要随机使用不同的划分方法重复p次，以均值作为k折交叉验证的评估结果

### 自助法
数据集 D，包含 m 个样本，对 D 采样 得到 D'：每次随机从 D 中挑选一个样本，将其深拷贝放入 D'，然后再将该样本放回初始数据集 D 中，是的该样本仍有可能被采样到。
* 自助法在数据集较小、难以有效划分 training/testing 时很有用
* 自助法能从初始数据集中产生多个不同的训练集，这对集成学习有很大好处
* 自助法改变了初始数据集的分布，会引入估计偏差，初始数据量足够时，留出法和交叉验证法更加常用

---
验证集(validation set)是用于模型评估与选择中，用于评估测试的数据集
测试集(testing set)是学得的模型在实际使用中遇到的数据成为测试数据

## 性能度量
回归任务最常用的性能度量是“均方误差”，有离散和连续两种表达形式
1. 错误率与精度
2. 查准率(precision)、查全率(recall)与 F1-socre
  混淆矩阵(confusion matrix)
  P-R曲线(查准率-查全率曲线)
  * 两个学习器的P-R曲线交叉，比较P-R曲线下面积的大小。
  * 平衡点(BEP)，越大，学习器越优，平衡点是 P=R 的点
  * F1-score，p-r的加权调和平均
多个二分类混淆矩阵或多次训练/测试得到的混淆矩阵或多个数据集上进行训练/测试，我们希望在n个二分类混淆矩阵上综合考察p和r
    > 1. 先在各cm上分别算p和r，再求均值，得到“宏查准/全率”(macro-P),“宏F1”(macro-F1)
    > 2. 先将各cm的四个对应元素进行平均，再基于这些平均值计算出对应“微查准/全率”(micro-P/R)，“微F1”（micro-F1）
3. ROC与AUC
ROC(Receiver Operation Characteristic)”受试者工作特征曲线“的纵轴：真正例率，TPR；横轴：假正例率，FPR
* P-R图相似，学习器能包住其他学习器的这个，性能较优
* 若ROC交叉，比较ROC曲线下的面积，即 AUC（area under ROC curve）
* AUC考虑的是样本预测的排序质量，与排序误差优紧密联系，loss考虑每一对儿正反例，正例预测值小于反例就记一个“1个惩罚”，如果相等记”0.5个惩罚“，lrank对应的是ROC曲线之上的面积；
4. 代价敏感错误率与代价曲线

## 比较检验
统计假设检验(hypothesis test)，基于假设检验结果可以推断出，若在testing set上观察到学习器A比B好，则A的泛化性能比在统计意义上优于B的把握有多大。
以错误率为性能度量
### 假设检验
"假设"是对学习器泛化错误率分布的某种判断或猜想，可以根据测试错误率估推出泛化错误率达分布
对于推导出的 m 个样本的testing set上，泛化错误率为 u 的学习器被测得测试错误率为 u0 的概率，符合二项分布，有二项检验的结论，a的显著度下，u <= u0 不能被拒绝，即在 a 的显著度下可以认为学习器的泛化错误率大于 u0
同样是多次使用留出法或交叉检验法，运用"t-test"：假定得到了k个测试错误率，则平均测试错误率和方差都可以知道，考虑到k个测试错误率可以看作泛化错误率达独立采样，则变量服从自由度为 k-1 的t分布
* 以上两种方法都是对于单个学习器泛化性能的假设进行检验
### 交叉验证t检验
对于两个学习器 A B，使用 k折交叉验证法得到测试错误率，对每一对儿结果求差，根据差值用"paried t-tests"进行比较检验，计算出差值对均值和方差，
若变量 t 小于临界值，则假设不能被拒绝，即认为两个学习器的性能没有显著差别；否则可以认为两个学习器的性能有显著差别，切平均错误率较小的学习器更优。
* 重要前提：测试错误率均为泛化错误率达独立采样
* 现实情况：使用交叉验证等的时候可能因为样本有限，从而不同轮次的训练集有一定程度的重叠，导致测试错误率实际上不独立，导致过高估计假设成立的概率。
解决办法： "5*2 交叉验证"：做5次2折交叉验证 [Dietterich, 1998]
### MCNemar 检验
对于二分类，留出法可以估计出“分类差别列联表”，如果两个学习器性能相同，那么$|e_{01} + e_{10}|$应该服从"卡方分布"
### Friedman 检验 与 Nemenyi 后续检验

## 偏差与方差
bias-variance decomposition （偏差-方差分解）是解释学习算法泛化性能的一种重要工具
偏差度量了学习算法的**期望预测**与**真实结果**的偏离程度，也就是刻画了学习算法本身的拟合能力
方差度量了同样大小的训练集的变动所导致的学习性能的变化，也就是刻画了数据扰动所造成的影响
噪声表达了当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度
偏差-方差分解说明泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的

